{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab25fef3"
      },
      "source": [
        "# Task\n",
        "Build a spam email classifier by loading a publicly available dataset, extracting features using Bag-of-Words or TF-IDF, training a machine learning model (e.g., Naive Bayes, SVM, or Logistic Regression), evaluating its performance using metrics like accuracy, precision, recall, and F1-score, and finally summarizing the model's strengths, weaknesses, and potential improvements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acdab04a"
      },
      "source": [
        "## Load Dataset\n",
        "\n",
        "### Subtask:\n",
        "Acquire and load a publicly available spam email dataset (e.g., SpamAssassin) into a suitable data structure for processing. Split the dataset into training and testing sets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ed049ff"
      },
      "source": [
        "### Acquire and Load Dataset\n",
        "\n",
        "For this task, we will use a publicly available spam email dataset. A widely used dataset is the [Enron Spam Dataset](https://www.cs.cmu.edu/~enron/).\n",
        "\n",
        "**Instructions:**\n",
        "1. Download a suitable version of the Enron Spam Dataset (e.g., a version that is already preprocessed into a CSV or text file format, if available, otherwise manual parsing might be needed).\n",
        "2. If you find a dataset in a different format (e.g., individual `.txt` files for spam and ham), you will need to combine them into a single structure that can be loaded into a pandas DataFrame.\n",
        "3. For simplicity, if you have a CSV file, ensure it has at least two columns: one for the email content and one for the spam/ham label (e.g., 'text' and 'label').\n",
        "\n",
        "Once downloaded, rename the dataset file to `spam_emails.csv` and place it in the working directory. If you are using a different dataset or file name, please adjust the next code block accordingly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88e0add7"
      },
      "source": [
        "**Reasoning**:\n",
        "The next step is to load the dataset, display its head, information, and value counts of the label column to understand its structure as per the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d02ff6b9",
        "outputId": "d8bb6bf7-0600-4cbc-81f2-84735637c766"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "try:\n",
        "    df = pd.read_csv('spam_emails.csv')\n",
        "    print(\"Dataset loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'spam_emails.csv' not found. Please ensure the dataset is in the working directory and named correctly.\")\n",
        "    print(\"You might need to adjust the file path or name.\")\n",
        "    # Create a dummy DataFrame for demonstration if the file is not found\n",
        "    # In a real scenario, the user would need to resolve the file issue.\n",
        "    data = {'text': ['Free money now!', 'Meeting tomorrow at 10 AM', 'Claim your prize', 'Project deadline is Friday'],\n",
        "            'label': [1, 0, 1, 0]}\n",
        "    df = pd.DataFrame(data)\n",
        "    print(\"Using a dummy DataFrame for demonstration purposes.\")\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(\"\\nFirst 5 rows of the dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "# Display column names and data types\n",
        "print(\"\\nDataFrame Info:\")\n",
        "df.info()\n",
        "\n",
        "# Display value counts for the 'label' column (assuming 'label' is the target column)\n",
        "if 'label' in df.columns:\n",
        "    print(\"\\nValue counts for the 'label' column:\")\n",
        "    print(df['label'].value_counts())\n",
        "else:\n",
        "    print(\"\\n'label' column not found. Please verify the name of your target column.\")\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: 'spam_emails.csv' not found. Please ensure the dataset is in the working directory and named correctly.\n",
            "You might need to adjust the file path or name.\n",
            "Using a dummy DataFrame for demonstration purposes.\n",
            "\n",
            "First 5 rows of the dataset:\n",
            "                         text  label\n",
            "0             Free money now!      1\n",
            "1   Meeting tomorrow at 10 AM      0\n",
            "2            Claim your prize      1\n",
            "3  Project deadline is Friday      0\n",
            "\n",
            "DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4 entries, 0 to 3\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    4 non-null      object\n",
            " 1   label   4 non-null      int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 196.0+ bytes\n",
            "\n",
            "Value counts for the 'label' column:\n",
            "label\n",
            "1    2\n",
            "0    2\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aedf9dea"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step loaded a dummy DataFrame because the actual CSV file was not found. Now, as per the subtask, I need to separate the features ('text' column) and the target variable ('label' column) from the DataFrame and then split the dataset into training and testing sets using `train_test_split`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "126cb2bc",
        "outputId": "4fd9c401-3c5b-4d8d-da37-78111e468c5a"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming 'df' DataFrame is already loaded from the previous step\n",
        "# Separate features (X) and target (y)\n",
        "X = df['text']\n",
        "y = df['label']\n",
        "\n",
        "print(\"Features (X) head:\")\n",
        "print(X.head())\n",
        "print(\"\\nTarget (y) head:\")\n",
        "print(y.head())\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "# Adjusted test_size to 0.5 to allow for stratification with 2 classes for the small dummy dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"\\nShape of X_train: {X_train.shape}\")\n",
        "print(f\"Shape of X_test: {X_test.shape}\")\n",
        "print(f\"Shape of y_train: {y_train.shape}\")\n",
        "print(f\"Shape of y_test: {y_test.shape}\")\n",
        "\n",
        "print(\"\\nDataset split into training and testing sets successfully.\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features (X) head:\n",
            "0               Free money now!\n",
            "1     Meeting tomorrow at 10 AM\n",
            "2              Claim your prize\n",
            "3    Project deadline is Friday\n",
            "Name: text, dtype: object\n",
            "\n",
            "Target (y) head:\n",
            "0    1\n",
            "1    0\n",
            "2    1\n",
            "3    0\n",
            "Name: label, dtype: int64\n",
            "\n",
            "Shape of X_train: (2,)\n",
            "Shape of X_test: (2,)\n",
            "Shape of y_train: (2,)\n",
            "Shape of y_test: (2,)\n",
            "\n",
            "Dataset split into training and testing sets successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "725bf637"
      },
      "source": [
        "## Feature Extraction\n",
        "\n",
        "### Subtask:\n",
        "Preprocess the email text by cleaning and tokenizing. Extract features from the email text and headers using techniques such as Bag-of-Words or TF-IDF. This step will transform raw text into numerical features suitable for machine learning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0683f5d7"
      },
      "source": [
        "### Acquire and Load Dataset\n",
        "\n",
        "For this task, we will use a publicly available spam email dataset. A widely used dataset is the [Enron Spam Dataset](https://www.cs.cmu.edu/~enron/).\n",
        "\n",
        "**Instructions:**\n",
        "1. Download a suitable version of the Enron Spam Dataset (e.g., a version that is already preprocessed into a CSV or text file format, if available, otherwise manual parsing might be needed).\n",
        "2. If you find a dataset in a different format (e.g., individual `.txt` files for spam and ham), you will need to combine them into a single structure that can be loaded into a pandas DataFrame.\n",
        "3. For simplicity, if you have a CSV file, ensure it has at least two columns: one for the email content and one for the spam/ham label (e.g., 'text' and 'label').\n",
        "\n",
        "Once downloaded, rename the dataset file to `spam_emails.csv` and place it in the working directory. If you are using a different dataset or file name, please adjust the next code block accordingly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bee53d7"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires preprocessing the email text and extracting features using TF-IDF. This step involves importing `TfidfVectorizer`, instantiating it, fitting it to the training data, and then transforming both the training and testing sets into TF-IDF feature matrices, as outlined in the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0fe5a01",
        "outputId": "1bbdc6c1-cc0f-4023-ff1f-60c3bc725257"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Instantiate TfidfVectorizer\n",
        "# Using stop_words='english' to remove common English words\n",
        "# max_features is set to a small number for the dummy dataset, in a real scenario, this would be higher\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
        "\n",
        "# Fit the vectorizer to the training data\n",
        "tfidf_vectorizer.fit(X_train)\n",
        "\n",
        "# Transform both training and testing data\n",
        "X_train_tfidf = tfidf_vectorizer.transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "print(\"TF-IDF vectorization complete.\")\n",
        "print(f\"Shape of X_train_tfidf: {X_train_tfidf.shape}\")\n",
        "print(f\"Shape of X_test_tfidf: {X_test_tfidf.shape}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF vectorization complete.\n",
            "Shape of X_train_tfidf: (2, 5)\n",
            "Shape of X_test_tfidf: (2, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "577a8742"
      },
      "source": [
        "## Train Classification Model\n",
        "\n",
        "### Subtask:\n",
        "Choose and train a machine learning model (e.g., Naive Bayes, Support Vector Machine, or Logistic Regression) on the extracted features from the training dataset using scikit-learn. This step will involve fitting the model to classify emails as spam or not spam.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c93493a"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires choosing and training a machine learning model. Following the instructions, I will import and instantiate the `MultinomialNB` model and then train it using the previously vectorized training data (`X_train_tfidf`) and labels (`y_train`).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f8e72e2",
        "outputId": "d0956c8d-5aa2-4f69-9e82-7626c23bbd26"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Instantiate the Multinomial Naive Bayes model\n",
        "nb_model = MultinomialNB()\n",
        "\n",
        "# Train the model\n",
        "nb_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "print(\"Multinomial Naive Bayes model trained successfully.\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multinomial Naive Bayes model trained successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3431c1b"
      },
      "source": [
        "## Evaluate Model Performance\n",
        "\n",
        "### Subtask:\n",
        "Evaluate the trained model's performance on the held-out test set. Calculate and visualize key metrics such as accuracy, precision, recall, F1-score, and generate a confusion matrix to understand the model's effectiveness.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c216217f"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires evaluating the trained model. This step will make predictions on the test set, then calculate and print key evaluation metrics (accuracy, precision, recall, F1-score) and the confusion matrix using `sklearn.metrics` as per the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea140542",
        "outputId": "d3dc6067-d871-4c8d-bce1-a6fa930aef02"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = nb_model.predict(X_test_tfidf)\n",
        "\n",
        "print(\"Model predictions generated.\")\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='binary') # or 'weighted' / 'macro'\n",
        "recall = recall_score(y_test, y_pred, average='binary')      # or 'weighted' / 'macro'\n",
        "f1 = f1_score(y_test, y_pred, average='binary')              # or 'weighted' / 'macro'\n",
        "\n",
        "# Print the metrics\n",
        "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "\n",
        "# Generate and print the confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model predictions generated.\n",
            "\n",
            "Accuracy: 0.5000\n",
            "Precision: 0.0000\n",
            "Recall: 0.0000\n",
            "F1-Score: 0.0000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1 0]\n",
            " [1 0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "756c15b7"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code block produced an `UndefinedMetricWarning` because precision, recall, and F1-score were ill-defined due to zero predicted samples for the positive class in the small dummy dataset. To handle this gracefully and prevent the warning, I will explicitly set `zero_division=0` in the calculation of these metrics.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7086e098",
        "outputId": "5c5c513c-476b-443f-dcb6-341433e0e8a4"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = nb_model.predict(X_test_tfidf)\n",
        "\n",
        "print(\"Model predictions generated.\")\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "# Setting zero_division=0 to explicitly handle cases where there are no positive predictions or true positives\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='binary', zero_division=0)\n",
        "recall = recall_score(y_test, y_pred, average='binary', zero_division=0)\n",
        "f1 = f1_score(y_test, y_pred, average='binary', zero_division=0)\n",
        "\n",
        "# Print the metrics\n",
        "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "\n",
        "# Generate and print the confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model predictions generated.\n",
            "\n",
            "Accuracy: 0.5000\n",
            "Precision: 0.0000\n",
            "Recall: 0.0000\n",
            "F1-Score: 0.0000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1 0]\n",
            " [1 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b400b851"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask explicitly asks to visualize the confusion matrix to better understand the model's effectiveness. Plotting the confusion matrix using `matplotlib` and `seaborn` will provide a clear visual representation of the model's performance on the test set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "229994dd",
        "outputId": "c4e7c755-1f94-4960-f785-63be489da52f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Visualize the confusion matrix\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "print(\"Confusion matrix visualized successfully.\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix visualized successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bd47383"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Provide a summary of the model's performance, discussing its strengths and weaknesses in detecting spam emails, and suggest potential areas for improvement or further extensions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77c4ab27"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "The model's performance on the small dummy dataset indicated a complete failure to detect spam emails. Its accuracy was 0.5000, with precision, recall, and F1-score all at 0.0000. The confusion matrix showed one true negative and one false negative, meaning the model consistently predicted all samples as non-spam. This effectively means the model has no strengths in detecting spam given the current setup and test data. Its primary weakness is its inability to identify any positive (spam) cases.\n",
        "\n",
        "Potential areas for improvement or further extensions include:\n",
        "*   **Using a real dataset**: The most critical improvement is to replace the dummy dataset with a comprehensive, real-world spam email dataset to enable meaningful training and evaluation.\n",
        "*   **Feature Engineering**: Experiment with different TF-IDF parameters (e.g., `max_features`, `ngram_range`) or explore other feature extraction techniques like Bag-of-Words or word embeddings.\n",
        "*   **Model Selection and Tuning**: Evaluate other machine learning models such as Support Vector Machines (SVMs) or Logistic Regression, and perform hyperparameter tuning to optimize performance.\n",
        "*   **Error Analysis**: Once a real dataset is used and a base model is established, conduct thorough error analysis on misclassified emails to identify patterns and guide further improvements.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   **Dataset Loading Issue**: The primary `spam_emails.csv` dataset was not found, leading to the creation and use of a small, 4-entry dummy DataFrame for subsequent steps. This dummy dataset contained two \"spam\" (label 1) and two \"ham\" (label 0) entries.\n",
        "*   **Data Splitting Adjustment**: The `train_test_split` function initially failed with `test_size=0.25` due to the small dataset size and `stratify` requirement. This was resolved by adjusting `test_size` to 0.5, resulting in training and testing sets each containing 2 samples.\n",
        "*   **TF-IDF Feature Extraction**: TF-IDF (Term Frequency-Inverse Document Frequency) was used to extract features. The `TfidfVectorizer` was configured to remove English stopwords and limited to `max_features=1000`. Due to the tiny dummy dataset, the resulting feature matrices (`X_train_tfidf` and `X_test_tfidf`) both had a shape of (2, 5), indicating only 5 features were extracted.\n",
        "*   **Model Training**: A Multinomial Naive Bayes model was successfully instantiated and trained on the extracted TF-IDF features.\n",
        "*   **Model Evaluation on Dummy Data**: On the small dummy test set, the model exhibited the following performance metrics:\n",
        "    *   Accuracy: 0.5000\n",
        "    *   Precision: 0.0000\n",
        "    *   Recall: 0.0000\n",
        "    *   F1-Score: 0.0000\n",
        "*   **Confusion Matrix**: The confusion matrix was `[[1 0], [1 0]]`, which implies that for the 2 test samples, the model correctly identified one non-spam email (True Negative) but incorrectly classified one spam email as non-spam (False Negative). It failed to identify any True Positives or False Positives.\n",
        "*   **Warning Handling**: An `UndefinedMetricWarning` for precision was encountered and addressed by setting `zero_division=0` in the `precision_score`, `recall_score`, and `f1_score` calculations, ensuring graceful handling when no positive predictions are made.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The current model performance is not meaningful for spam detection due to the use of a very small dummy dataset. The immediate next step is to acquire and load a real, substantial spam email dataset.\n",
        "*   With a proper dataset, the model's performance should be re-evaluated. If the initial poor performance persists, it would be crucial to experiment with alternative feature extraction techniques, different machine learning models, and hyperparameter tuning.\n"
      ]
    }
  ]
}