{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d061a78a"
      },
      "source": [
        "# Task\n",
        "Build a movie recommendation system using the MovieLens dataset, employing user-based collaborative filtering to generate recommendations for a target user, and finally, summarize the implemented system."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "935faeaa",
        "outputId": "4d234973-dfc2-42ac-d76a-adbe845a8491"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Download the dataset if not already present\n",
        "!wget -nc https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
        "!unzip -n ml-latest-small.zip\n",
        "\n",
        "# Load the 'ratings.csv' file into a pandas DataFrame\n",
        "ratings_df = pd.read_csv('ml-latest-small/ratings.csv')\n",
        "\n",
        "# Display the first 5 rows of the DataFrame\n",
        "print('First 5 rows of the DataFrame:')\n",
        "print(ratings_df.head())\n",
        "\n",
        "# Print the concise summary of the DataFrame\n",
        "print('\\nDataFrame Info:')\n",
        "ratings_df.info()\n",
        "\n",
        "# Check for any missing values in the DataFrame\n",
        "print('\\nMissing values per column:')\n",
        "print(ratings_df.isnull().sum())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-02-03 14:26:37--  https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.96.204\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.96.204|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 978202 (955K) [application/zip]\n",
            "Saving to: ‘ml-latest-small.zip’\n",
            "\n",
            "ml-latest-small.zip 100%[===================>] 955.28K  3.30MB/s    in 0.3s    \n",
            "\n",
            "2026-02-03 14:26:37 (3.30 MB/s) - ‘ml-latest-small.zip’ saved [978202/978202]\n",
            "\n",
            "Archive:  ml-latest-small.zip\n",
            "   creating: ml-latest-small/\n",
            "  inflating: ml-latest-small/links.csv  \n",
            "  inflating: ml-latest-small/tags.csv  \n",
            "  inflating: ml-latest-small/ratings.csv  \n",
            "  inflating: ml-latest-small/README.txt  \n",
            "  inflating: ml-latest-small/movies.csv  \n",
            "First 5 rows of the DataFrame:\n",
            "   userId  movieId  rating  timestamp\n",
            "0       1        1     4.0  964982703\n",
            "1       1        3     4.0  964981247\n",
            "2       1        6     4.0  964982224\n",
            "3       1       47     5.0  964983815\n",
            "4       1       50     5.0  964982931\n",
            "\n",
            "DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100836 entries, 0 to 100835\n",
            "Data columns (total 4 columns):\n",
            " #   Column     Non-Null Count   Dtype  \n",
            "---  ------     --------------   -----  \n",
            " 0   userId     100836 non-null  int64  \n",
            " 1   movieId    100836 non-null  int64  \n",
            " 2   rating     100836 non-null  float64\n",
            " 3   timestamp  100836 non-null  int64  \n",
            "dtypes: float64(1), int64(3)\n",
            "memory usage: 3.1 MB\n",
            "\n",
            "Missing values per column:\n",
            "userId       0\n",
            "movieId      0\n",
            "rating       0\n",
            "timestamp    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bce9f8f",
        "outputId": "967316f3-92d7-4696-e83a-3dd0e267dbc1"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Calculate the number of ratings per user\n",
        "user_ratings_count = ratings_df['userId'].value_counts()\n",
        "print('\\nNumber of ratings per user (top 10):')\n",
        "print(user_ratings_count.head(10))\n",
        "print('\\nNumber of ratings per user (bottom 10):')\n",
        "print(user_ratings_count.tail(10))\n",
        "\n",
        "# Calculate the number of ratings per movie\n",
        "movie_ratings_count = ratings_df['movieId'].value_counts()\n",
        "print('\\nNumber of ratings per movie (top 10):')\n",
        "print(movie_ratings_count.head(10))\n",
        "print('\\nNumber of ratings per movie (bottom 10):')\n",
        "print(movie_ratings_count.tail(10))\n",
        "\n",
        "# Define thresholds for filtering sparse data\n",
        "# A common practice is to remove users who have rated very few movies\n",
        "# and movies that have been rated by very few users.\n",
        "# Let's choose thresholds: users with less than 20 ratings and movies with less than 10 ratings.\n",
        "user_threshold = 20\n",
        "movie_threshold = 10\n",
        "\n",
        "# Identify users and movies to keep\n",
        "active_users = user_ratings_count[user_ratings_count >= user_threshold].index\n",
        "popular_movies = movie_ratings_count[movie_ratings_count >= movie_threshold].index\n",
        "\n",
        "# Filter the original DataFrame\n",
        "filtered_ratings_df = ratings_df[\n",
        "    ratings_df['userId'].isin(active_users) &\n",
        "    ratings_df['movieId'].isin(popular_movies)\n",
        "]\n",
        "\n",
        "print(f'\\nOriginal DataFrame shape: {ratings_df.shape}')\n",
        "print(f'Filtered DataFrame shape: {filtered_ratings_df.shape}')\n",
        "print(f'Number of users before filtering: {ratings_df[\"userId\"].nunique()}')\n",
        "print(f'Number of users after filtering: {filtered_ratings_df[\"userId\"].nunique()}')\n",
        "print(f'Number of movies before filtering: {ratings_df[\"movieId\"].nunique()}')\n",
        "print(f'Number of movies after filtering: {filtered_ratings_df[\"movieId\"].nunique()}')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of ratings per user (top 10):\n",
            "userId\n",
            "414    2698\n",
            "599    2478\n",
            "474    2108\n",
            "448    1864\n",
            "274    1346\n",
            "610    1302\n",
            "68     1260\n",
            "380    1218\n",
            "606    1115\n",
            "288    1055\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Number of ratings per user (bottom 10):\n",
            "userId\n",
            "406    20\n",
            "576    20\n",
            "569    20\n",
            "595    20\n",
            "207    20\n",
            "442    20\n",
            "278    20\n",
            "147    20\n",
            "320    20\n",
            "53     20\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Number of ratings per movie (top 10):\n",
            "movieId\n",
            "356     329\n",
            "318     317\n",
            "296     307\n",
            "593     279\n",
            "2571    278\n",
            "260     251\n",
            "480     238\n",
            "110     237\n",
            "589     224\n",
            "527     220\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Number of ratings per movie (bottom 10):\n",
            "movieId\n",
            "160684    1\n",
            "173317    1\n",
            "179135    1\n",
            "184245    1\n",
            "188675    1\n",
            "188833    1\n",
            "189381    1\n",
            "3899      1\n",
            "2848      1\n",
            "147002    1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Original DataFrame shape: (100836, 4)\n",
            "Filtered DataFrame shape: (81116, 4)\n",
            "Number of users before filtering: 610\n",
            "Number of users after filtering: 610\n",
            "Number of movies before filtering: 9724\n",
            "Number of movies after filtering: 2269\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4935cbf",
        "outputId": "57e784e0-9520-4343-9a50-292fd7b5a7ab"
      },
      "source": [
        "user_movie_matrix = filtered_ratings_df.pivot_table(index='userId', columns='movieId', values='rating')\n",
        "\n",
        "print('User-Item Interaction Matrix (first 5 rows and a few columns):')\n",
        "print(user_movie_matrix.iloc[:5, :10])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User-Item Interaction Matrix (first 5 rows and a few columns):\n",
            "movieId   1   2    3   5    6   7   9   10  11  12\n",
            "userId                                            \n",
            "1        4.0 NaN  4.0 NaN  4.0 NaN NaN NaN NaN NaN\n",
            "2        NaN NaN  NaN NaN  NaN NaN NaN NaN NaN NaN\n",
            "3        NaN NaN  NaN NaN  NaN NaN NaN NaN NaN NaN\n",
            "4        NaN NaN  NaN NaN  NaN NaN NaN NaN NaN NaN\n",
            "5        4.0 NaN  NaN NaN  NaN NaN NaN NaN NaN NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83742be6",
        "outputId": "9e7e62b9-9041-410c-b222-08205357a978"
      },
      "source": [
        "user_movie_matrix_filled = user_movie_matrix.fillna(0)\n",
        "\n",
        "print('User-Item Interaction Matrix after filling NaNs with zeros (first 5 rows and a few columns):')\n",
        "print(user_movie_matrix_filled.iloc[:5, :10])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User-Item Interaction Matrix after filling NaNs with zeros (first 5 rows and a few columns):\n",
            "movieId   1    2    3    5    6    7    9    10   11   12\n",
            "userId                                                   \n",
            "1        4.0  0.0  4.0  0.0  4.0  0.0  0.0  0.0  0.0  0.0\n",
            "2        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "3        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "4        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "5        4.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff6b8d45",
        "outputId": "6a78f3d1-0557-4b1f-bf1f-68187cf81c52"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Calculate the cosine similarity between users\n",
        "user_similarity_matrix = cosine_similarity(user_movie_matrix_filled)\n",
        "\n",
        "# Convert the similarity matrix to a Pandas DataFrame for better readability\n",
        "user_similarity_matrix = pd.DataFrame(\n",
        "    user_similarity_matrix,\n",
        "    index=user_movie_matrix.index,\n",
        "    columns=user_movie_matrix.index\n",
        ")\n",
        "\n",
        "print('User Similarity Matrix (first 5 rows and columns):')\n",
        "print(user_similarity_matrix.iloc[:5, :5])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User Similarity Matrix (first 5 rows and columns):\n",
            "userId         1         2         3         4         5\n",
            "userId                                                  \n",
            "1       1.000000  0.029977  0.115634  0.220630  0.134869\n",
            "2       0.029977  1.000000  0.000000  0.004256  0.017471\n",
            "3       0.115634  0.000000  1.000000  0.004532  0.009302\n",
            "4       0.220630  0.004256  0.004532  1.000000  0.139754\n",
            "5       0.134869  0.017471  0.009302  0.139754  1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d123d51",
        "outputId": "b8eb134d-f4c7-4041-8355-ec1bd7eb4a13"
      },
      "source": [
        "def predict_rating(user_id, movie_id, user_movie_matrix, user_similarity_matrix, k=5):\n",
        "    # Get similarity scores for the target user\n",
        "    user_sims = user_similarity_matrix[user_id]\n",
        "\n",
        "    # Get ratings for the target movie from all users\n",
        "    # Filter out NaNs to only consider users who have actually rated the movie\n",
        "    movie_ratings = user_movie_matrix[movie_id].dropna()\n",
        "\n",
        "    # Identify users who have rated the target movie and are not the target user\n",
        "    rated_by_others = movie_ratings.index.drop(user_id, errors='ignore')\n",
        "\n",
        "    if rated_by_others.empty:\n",
        "        # If no other user has rated this movie, or only the target user has,\n",
        "        # return NaN as a prediction cannot be made based on neighbors.\n",
        "        return np.nan\n",
        "\n",
        "    # Get similarity scores for users who rated the movie\n",
        "    relevant_sims = user_sims.loc[rated_by_others]\n",
        "\n",
        "    # Sort similar users by similarity in descending order and select top k neighbors\n",
        "    # Filter out users with 0 or negative similarity, as they don't contribute positively\n",
        "    relevant_sims_filtered = relevant_sims[relevant_sims > 0].sort_values(ascending=False)\n",
        "\n",
        "    if relevant_sims_filtered.empty:\n",
        "        return np.nan # No similar users with positive similarity\n",
        "\n",
        "    top_k_neighbors = relevant_sims_filtered.head(k).index\n",
        "\n",
        "    # Ensure these top k neighbors actually rated the movie and have a valid rating\n",
        "    final_neighbors = top_k_neighbors.intersection(movie_ratings.index)\n",
        "\n",
        "    if final_neighbors.empty:\n",
        "        return np.nan\n",
        "\n",
        "    # Get similarities and ratings for the final neighbors\n",
        "    sim_scores = relevant_sims.loc[final_neighbors]\n",
        "    neighbor_ratings = movie_ratings.loc[final_neighbors]\n",
        "\n",
        "    # Calculate weighted average\n",
        "    # Avoid division by zero if sum of similarities is zero\n",
        "    if sim_scores.abs().sum() == 0:\n",
        "        return np.nan\n",
        "\n",
        "    predicted_rating = (sim_scores * neighbor_ratings).sum() / sim_scores.abs().sum()\n",
        "    return predicted_rating\n",
        "\n",
        "# Example: Predict a rating for user 1 for a movie they haven't rated\n",
        "target_user_id = 1\n",
        "\n",
        "# Find a movie not rated by the target user\n",
        "unrated_movies_for_target_user = user_movie_matrix.loc[target_user_id][user_movie_matrix.loc[target_user_id].isna()]\n",
        "\n",
        "if not unrated_movies_for_target_user.empty:\n",
        "    # Get the ID of the first unrated movie\n",
        "    target_movie_id = unrated_movies_for_target_user.index[0]\n",
        "    print(f\"\\nAttempting to predict rating for User {target_user_id} for Movie {target_movie_id}.\")\n",
        "\n",
        "    # Predict the rating\n",
        "    predicted_rating = predict_rating(target_user_id, target_movie_id, user_movie_matrix, user_similarity_matrix)\n",
        "\n",
        "    if not np.isnan(predicted_rating):\n",
        "        print(f\"Predicted rating for User {target_user_id} for Movie {target_movie_id}: {predicted_rating:.2f}\")\n",
        "    else:\n",
        "        print(f\"Could not predict rating for User {target_user_id} for Movie {target_movie_id} (not enough similar users or data).\")\n",
        "else:\n",
        "    print(f\"User {target_user_id} has rated all available movies or no unrated movies found with current filtering for prediction.\")\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Attempting to predict rating for User 1 for Movie 2.\n",
            "Predicted rating for User 1 for Movie 2: 2.50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf67e652",
        "outputId": "5ecd4180-681a-45c4-e232-4a8349af8901"
      },
      "source": [
        "def generate_recommendations(user_id, user_movie_matrix, user_similarity_matrix, num_recommendations=10, k=5):\n",
        "    # Get movies the user has already rated\n",
        "    rated_movies = user_movie_matrix.loc[user_id].dropna().index\n",
        "\n",
        "    # Get all movie IDs present in the matrix\n",
        "    all_movie_ids = user_movie_matrix.columns\n",
        "\n",
        "    # Identify movies the user has not rated\n",
        "    unrated_movies = [movie_id for movie_id in all_movie_ids if movie_id not in rated_movies]\n",
        "\n",
        "    predictions = {}\n",
        "    for movie_id in unrated_movies:\n",
        "        predicted_rating = predict_rating(user_id, movie_id, user_movie_matrix, user_similarity_matrix, k)\n",
        "        if not np.isnan(predicted_rating):\n",
        "            predictions[movie_id] = predicted_rating\n",
        "\n",
        "    # Sort predictions by rating in descending order\n",
        "    sorted_predictions = sorted(predictions.items(), key=lambda item: item[1], reverse=True)\n",
        "\n",
        "    # Get the top N recommendations\n",
        "    top_recommendations = sorted_predictions[:num_recommendations]\n",
        "\n",
        "    return top_recommendations\n",
        "\n",
        "# Generate recommendations for the target user (e.g., User 1)\n",
        "target_user_id = 1\n",
        "num_recommendations = 10\n",
        "\n",
        "print(f\"\\nGenerating top {num_recommendations} recommendations for User {target_user_id}...\")\n",
        "recommendations = generate_recommendations(target_user_id, user_movie_matrix, user_similarity_matrix, num_recommendations=num_recommendations)\n",
        "\n",
        "if recommendations:\n",
        "    print(f\"Top {num_recommendations} recommendations for User {target_user_id}:\")\n",
        "    for movie_id, predicted_rating in recommendations:\n",
        "        print(f\"  Movie ID: {movie_id}, Predicted Rating: {predicted_rating:.2f}\")\n",
        "else:\n",
        "    print(f\"Could not generate recommendations for User {target_user_id}. Either no unrated movies or not enough data for prediction.\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generating top 10 recommendations for User 1...\n",
            "Top 10 recommendations for User 1:\n",
            "  Movie ID: 1200, Predicted Rating: 4.80\n",
            "  Movie ID: 541, Predicted Rating: 4.80\n",
            "  Movie ID: 92535, Predicted Rating: 4.80\n",
            "  Movie ID: 3030, Predicted Rating: 4.71\n",
            "  Movie ID: 4973, Predicted Rating: 4.71\n",
            "  Movie ID: 750, Predicted Rating: 4.70\n",
            "  Movie ID: 7387, Predicted Rating: 4.61\n",
            "  Movie ID: 1235, Predicted Rating: 4.61\n",
            "  Movie ID: 1203, Predicted Rating: 4.60\n",
            "  Movie ID: 1244, Predicted Rating: 4.60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "682aaf5e",
        "outputId": "0c1c4039-2a4d-474f-ce24-30d20e25aa0f"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the filtered_ratings_df into training and testing sets (80% train, 20% test)\n",
        "train_df, test_df = train_test_split(filtered_ratings_df, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f'Shape of training data: {train_df.shape}')\n",
        "print(f'Shape of test data: {test_df.shape}')\n",
        "print('Data split into training and testing sets.')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of training data: (64892, 4)\n",
            "Shape of test data: (16224, 4)\n",
            "Data split into training and testing sets.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d780028",
        "outputId": "c5ad6d60-a7ed-4012-94bc-3f25e990163d"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Reconstruct user_movie_matrix using only the training data\n",
        "user_movie_matrix_train = train_df.pivot_table(index='userId', columns='movieId', values='rating')\n",
        "\n",
        "# Fill NaN values with zeros\n",
        "user_movie_matrix_train_filled = user_movie_matrix_train.fillna(0)\n",
        "\n",
        "# Calculate user similarity matrix based on training data\n",
        "user_similarity_matrix_train = pd.DataFrame(\n",
        "    cosine_similarity(user_movie_matrix_train_filled),\n",
        "    index=user_movie_matrix_train.index,\n",
        "    columns=user_movie_matrix_train.index\n",
        ")\n",
        "\n",
        "print('User-Movie Matrix for Training Data (first 5 rows and a few columns):')\n",
        "print(user_movie_matrix_train.iloc[:5, :10])\n",
        "print('\\nUser Similarity Matrix for Training Data (first 5 rows and columns):')\n",
        "print(user_similarity_matrix_train.iloc[:5, :5])\n",
        "\n",
        "# Prepare lists to store actual and predicted ratings\n",
        "actual_ratings = []\n",
        "predicted_ratings = []\n",
        "\n",
        "# Iterate through the test set to make predictions\n",
        "print('\\nMaking predictions on the test set...')\n",
        "for index, row in test_df.iterrows():\n",
        "    user_id = int(row['userId'])\n",
        "    movie_id = int(row['movieId'])\n",
        "    actual_rating = row['rating']\n",
        "\n",
        "    # Predict rating using the function defined earlier\n",
        "    # Ensure the user and movie exist in the training matrix before predicting\n",
        "    if user_id in user_movie_matrix_train.index and movie_id in user_movie_matrix_train.columns:\n",
        "        predicted = predict_rating(user_id, movie_id, user_movie_matrix_train, user_similarity_matrix_train)\n",
        "\n",
        "        if not np.isnan(predicted):\n",
        "            actual_ratings.append(actual_rating)\n",
        "            predicted_ratings.append(predicted)\n",
        "\n",
        "# Calculate RMSE\n",
        "if actual_ratings and predicted_ratings:\n",
        "    rmse = np.sqrt(mean_squared_error(actual_ratings, predicted_ratings))\n",
        "    print(f'\\nRoot Mean Squared Error (RMSE): {rmse:.4f}')\n",
        "else:\n",
        "    print('\\nNo valid predictions could be made for the test set.')\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User-Movie Matrix for Training Data (first 5 rows and a few columns):\n",
            "movieId   1   2    3   5    6   7   9   10  11  12\n",
            "userId                                            \n",
            "1        4.0 NaN  4.0 NaN  4.0 NaN NaN NaN NaN NaN\n",
            "2        NaN NaN  NaN NaN  NaN NaN NaN NaN NaN NaN\n",
            "3        NaN NaN  NaN NaN  NaN NaN NaN NaN NaN NaN\n",
            "4        NaN NaN  NaN NaN  NaN NaN NaN NaN NaN NaN\n",
            "5        4.0 NaN  NaN NaN  NaN NaN NaN NaN NaN NaN\n",
            "\n",
            "User Similarity Matrix for Training Data (first 5 rows and columns):\n",
            "userId         1         2         3         4         5\n",
            "userId                                                  \n",
            "1       1.000000  0.018668  0.118326  0.183240  0.131963\n",
            "2       0.018668  1.000000  0.000000  0.000000  0.000000\n",
            "3       0.118326  0.000000  1.000000  0.004937  0.012565\n",
            "4       0.183240  0.000000  0.004937  1.000000  0.081994\n",
            "5       0.131963  0.000000  0.012565  0.081994  1.000000\n",
            "\n",
            "Making predictions on the test set...\n",
            "\n",
            "Root Mean Squared Error (RMSE): 0.9778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22204b31"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Summarize the basic recommendation system built, including the algorithm used and the insights gained from the process.\n"
      ]
    }
  ]
}