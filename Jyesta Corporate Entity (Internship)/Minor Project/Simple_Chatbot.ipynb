{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5dd29bd"
      },
      "source": [
        "# Task\n",
        "Develop a rule-based chatbot that uses a small dataset of question-answer pairs, applies basic NLP techniques like tokenization, stemming, and keyword extraction, and interacts with users through a command-line interface. Conclude by summarizing its capabilities and demonstrating its functionality with example interactions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6abb9d7a"
      },
      "source": [
        "## Data Collection\n",
        "\n",
        "### Subtask:\n",
        "Create a small dataset of question-answer pairs relevant to a specific domain for the chatbot to use. This dataset will serve as the knowledge base for the rule-based system.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56433990",
        "outputId": "8c1892fb-8467-439e-c1fd-866d133c5f8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question-Answer dataset created successfully.\n",
            "Number of Q&A pairs: 5\n",
            "First Q&A pair: {'question': 'What is the capital of France?', 'answer': 'The capital of France is Paris.'}\n"
          ]
        }
      ],
      "source": [
        "qa_dataset = [\n",
        "    {\"question\": \"What is the capital of France?\", \"answer\": \"The capital of France is Paris.\"},\n",
        "    {\"question\": \"Who painted the Mona Lisa?\", \"answer\": \"Leonardo da Vinci painted the Mona Lisa.\"},\n",
        "    {\"question\": \"What is the highest mountain in the world?\", \"answer\": \"Mount Everest is the highest mountain in the world.\"},\n",
        "    {\"question\": \"What is the chemical symbol for water?\", \"answer\": \"The chemical symbol for water is H2O.\"},\n",
        "    {\"question\": \"How many planets are in our solar system?\", \"answer\": \"There are eight planets in our solar system.\"}\n",
        "]\n",
        "\n",
        "print(\"Question-Answer dataset created successfully.\")\n",
        "print(f\"Number of Q&A pairs: {len(qa_dataset)}\")\n",
        "print(\"First Q&A pair:\", qa_dataset[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fb13f43"
      },
      "source": [
        "## Implement NLP Techniques\n",
        "\n",
        "### Subtask:\n",
        "Develop functions to apply basic NLP techniques such as tokenization, stemming, and keyword extraction to process user input.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ce91e14",
        "outputId": "e4dcfba3-fdda-46fa-e6da-f243b4bb575c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLTK 'punkt', 'stopwords', and 'punkt_tab' datasets downloaded/checked successfully.\n",
            "PorterStemmer instantiated.\n",
            "Loaded 198 English stopwords.\n",
            "NLP utility functions (tokenize_text, stem_tokens, extract_keywords) defined.\n",
            "\n",
            "Original input: 'What is the capital of France? I want to know about it.'\n",
            "Tokenized output: ['What', 'is', 'the', 'capital', 'of', 'France', '?', 'I', 'want', 'to', 'know', 'about', 'it', '.']\n",
            "Stemmed output: ['what', 'is', 'the', 'capit', 'of', 'franc', '?', 'i', 'want', 'to', 'know', 'about', 'it', '.']\n",
            "Extracted keywords: ['capit', 'know', 'want', 'franc']\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# 2. Download NLTK datasets if not already downloaded\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('punkt_tab', quiet=True) # Added to address LookupError for punkt_tab\n",
        "\n",
        "print(\"NLTK 'punkt', 'stopwords', and 'punkt_tab' datasets downloaded/checked successfully.\")\n",
        "\n",
        "# 3. Define tokenization function\n",
        "def tokenize_text(text):\n",
        "    return word_tokenize(text)\n",
        "\n",
        "# 4. Instantiate PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "print(\"PorterStemmer instantiated.\")\n",
        "\n",
        "# 5. Define stemming function\n",
        "def stem_tokens(tokens):\n",
        "    return [stemmer.stem(token) for token in tokens]\n",
        "\n",
        "# 6. Get English stopwords\n",
        "english_stopwords = set(stopwords.words('english'))\n",
        "print(f\"Loaded {len(english_stopwords)} English stopwords.\")\n",
        "\n",
        "# 7. Define keyword extraction function\n",
        "def extract_keywords(user_input):\n",
        "    # a. Tokenize the input string\n",
        "    tokens = tokenize_text(user_input)\n",
        "\n",
        "    # b. Convert all tokens to lowercase and c. Filter out stopwords and non-alphabetic tokens\n",
        "    filtered_tokens = [word.lower() for word in tokens if word.isalpha() and word.lower() not in english_stopwords]\n",
        "\n",
        "    # d. Stem the remaining tokens\n",
        "    stemmed_keywords = stem_tokens(filtered_tokens)\n",
        "\n",
        "    # e. Return the list of unique stemmed keywords\n",
        "    return list(set(stemmed_keywords))\n",
        "\n",
        "print(\"NLP utility functions (tokenize_text, stem_tokens, extract_keywords) defined.\")\n",
        "\n",
        "# Demonstrate functionality with an example\n",
        "example_input = \"What is the capital of France? I want to know about it.\"\n",
        "tokenized_example = tokenize_text(example_input)\n",
        "stemmed_example = stem_tokens(tokenized_example)\n",
        "keywords_example = extract_keywords(example_input)\n",
        "\n",
        "print(f\"\\nOriginal input: '{example_input}'\")\n",
        "print(f\"Tokenized output: {tokenized_example}\")\n",
        "print(f\"Stemmed output: {stemmed_example}\")\n",
        "print(f\"Extracted keywords: {keywords_example}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da90a286"
      },
      "source": [
        "## Build Rule-Based System\n",
        "\n",
        "### Subtask:\n",
        "Implement a rule-based system that uses the extracted keywords and patterns from user queries to map them to appropriate, predefined responses from the collected dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bec0710c",
        "outputId": "81c66045-21cc-4934-d8f7-417001bb6dbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed Q&A dataset created successfully with keywords.\n",
            "Number of processed Q&A pairs: 5\n",
            "First processed Q&A pair: {'question': 'What is the capital of France?', 'answer': 'The capital of France is Paris.', 'keywords': ['capit', 'franc']}\n"
          ]
        }
      ],
      "source": [
        "processed_qa_dataset = []\n",
        "for item in qa_dataset:\n",
        "    question_keywords = extract_keywords(item['question'])\n",
        "    processed_qa_dataset.append({\n",
        "        \"question\": item['question'],\n",
        "        \"answer\": item['answer'],\n",
        "        \"keywords\": question_keywords\n",
        "    })\n",
        "\n",
        "print(\"Processed Q&A dataset created successfully with keywords.\")\n",
        "print(f\"Number of processed Q&A pairs: {len(processed_qa_dataset)}\")\n",
        "print(\"First processed Q&A pair:\", processed_qa_dataset[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "131fe55d",
        "outputId": "341dacb6-c530-4583-bb48-58b5687552a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The 'find_answer' function has been defined.\n",
            "\n",
            "--- Testing find_answer function ---\n",
            "User: What is the capital of France?\n",
            "Chatbot: The capital of France is Paris.\n",
            "User: Who painted Mona Lisa?\n",
            "Chatbot: Leonardo da Vinci painted the Mona Lisa.\n",
            "User: Highest peak in the world?\n",
            "Chatbot: Mount Everest is the highest mountain in the world.\n",
            "User: Tell me about artificial intelligence.\n",
            "Chatbot: I'm sorry, I don't have an answer to that question.\n",
            "User: What is the weather like today?\n",
            "Chatbot: I'm sorry, I don't have an answer to that question.\n",
            "User: How many planets are there in our solar system right now?\n",
            "Chatbot: There are eight planets in our solar system.\n"
          ]
        }
      ],
      "source": [
        "def find_answer(user_query):\n",
        "    user_keywords = extract_keywords(user_query)\n",
        "    best_match_score = 0\n",
        "    best_answer = \"I'm sorry, I don't have an answer to that question.\"\n",
        "\n",
        "    if not user_keywords:\n",
        "        return best_answer\n",
        "\n",
        "    for item in processed_qa_dataset:\n",
        "        question_keywords = item['keywords']\n",
        "        # Calculate match score: number of common keywords\n",
        "        match_score = len(set(user_keywords).intersection(set(question_keywords)))\n",
        "\n",
        "        if match_score > best_match_score:\n",
        "            best_match_score = match_score\n",
        "            best_answer = item['answer']\n",
        "\n",
        "    # If no keywords matched (score remains 0) and the default answer is still present, ensure it's returned\n",
        "    if best_match_score == 0:\n",
        "        return \"I'm sorry, I don't have an answer to that question.\"\n",
        "    else:\n",
        "        return best_answer\n",
        "\n",
        "print(\"The 'find_answer' function has been defined.\")\n",
        "\n",
        "# Test the find_answer function with example queries\n",
        "print(\"\\n--- Testing find_answer function ---\")\n",
        "\n",
        "# Example 1: Clear match\n",
        "query1 = \"What is the capital of France?\"\n",
        "response1 = find_answer(query1)\n",
        "print(f\"User: {query1}\\nChatbot: {response1}\")\n",
        "\n",
        "# Example 2: Partial match / rephrased query\n",
        "query2 = \"Who painted Mona Lisa?\"\n",
        "response2 = find_answer(query2)\n",
        "print(f\"User: {query2}\\nChatbot: {response2}\")\n",
        "\n",
        "# Example 3: Different phrasing of an existing question\n",
        "query3 = \"Highest peak in the world?\"\n",
        "response3 = find_answer(query3)\n",
        "print(f\"User: {query3}\\nChatbot: {response3}\")\n",
        "\n",
        "# Example 4: Query with no match\n",
        "query4 = \"Tell me about artificial intelligence.\"\n",
        "response4 = find_answer(query4)\n",
        "print(f\"User: {query4}\\nChatbot: {response4}\")\n",
        "\n",
        "# Example 5: Another query with no match\n",
        "query5 = \"What is the weather like today?\"\n",
        "response5 = find_answer(query5)\n",
        "print(f\"User: {query5}\\nChatbot: {response5}\")\n",
        "\n",
        "# Example 6: Query with multiple common words but not enough matching keywords\n",
        "query6 = \"How many planets are there in our solar system right now?\"\n",
        "response6 = find_answer(query6)\n",
        "print(f\"User: {query6}\\nChatbot: {response6}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d5bcd6b"
      },
      "source": [
        "## Develop User Interface\n",
        "\n",
        "### Subtask:\n",
        "Create a simple command-line interface (CLI) that allows users to interact with the chatbot by typing queries and receiving responses.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c7eabc2",
        "outputId": "516cac6c-73a5-4227-ce58-bf3c7929b6fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Chatbot CLI Started ---\n",
            "Type 'quit', 'exit', or 'bye' to end the conversation.\n",
            "\n",
            "You: What is the capital of France?\n",
            "Chatbot: The capital of France is Paris.\n",
            "\n",
            "You: quiet\n",
            "Chatbot: I'm sorry, I don't have an answer to that question.\n",
            "\n",
            "You: quit\n",
            "Chatbot: Goodbye! Thanks for chatting.\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n--- Chatbot CLI Started ---\")\n",
        "print(\"Type 'quit', 'exit', or 'bye' to end the conversation.\")\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"\\nYou: \")\n",
        "    user_input_lower = user_input.lower()\n",
        "\n",
        "    if user_input_lower in ['quit', 'exit', 'bye']:\n",
        "        print(\"Chatbot: Goodbye! Thanks for chatting.\")\n",
        "        break\n",
        "    else:\n",
        "        response = find_answer(user_input)\n",
        "        print(f\"Chatbot: {response}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7b2e695"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Summarize the developed chatbot's capabilities, demonstrate its functionality with a few example interactions, and discuss potential next steps for improvement or extensions.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
